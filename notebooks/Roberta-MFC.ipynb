{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee33110",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab3f10816ba4ec69119b9f3afdc687c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e920e6b692e4ab69e9d5fbc331b09ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb969971af14006ab08bf3eb0951f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14d7aba7f6a4ad8a65200247b901429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44719534f6f49b4b29f94d381c496d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cdeaa767b440199a8418a4b7de155f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67e4b52c6a647c185bcd3c916387d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417b65a4536243eda35b255ef52fdfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b19e3b5ae247d5a5666f0a8c09acf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502ad195bdfa40f297fc0021d0c3c1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ed0c2f59464b1aaa630eb83c697b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3cf094916b4821b8a3cd6fee2ae031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c04d72c4cb413eb3f584adb1138503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8e23d94226488a9696832eac6ff4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3551909eb16b4d98887ab853a40abd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03375624 -0.06316338 -0.0316612  ...  0.03684864 -0.02036646\n",
      "  -0.01574   ]\n",
      " [-0.01409588  0.00091114 -0.00096315 ... -0.02571585 -0.00289072\n",
      "  -0.00579975]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
    "model.eval()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64afc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 768)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3efe1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f6de15ff200>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b05af856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "all_spans = {}\n",
    "\n",
    "with open(\"../../mfc_v4.0/spans_no_context.json\", \"r\") as f:\n",
    "    all_spans = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cd94574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   713,    16,    41,  1246,  3645,     2],\n",
       "        [    0, 20319,  3645,    16,  8417,     2,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddbeaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as NN\n",
    "\n",
    "\n",
    "class SentenceClassifier(NN.Module):\n",
    "    def __init__(self, labels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformer = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
    "        for params in self.transformer.parameters():\n",
    "            params.requires_grad = False\n",
    "        \n",
    "        self.fc = NN.Linear(768, len(labels))\n",
    "        self.logits = NN.Softmax()\n",
    "        self.labels = labels\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.logits(self.fc(torch.tensor(self.transformer.encode(x))))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "\n",
    "# count = 0\n",
    "\n",
    "# n_spans = sum(len(all_spans[key]) for key in all_spans)\n",
    "\n",
    "# batch_x = []\n",
    "# batch_y = []\n",
    "\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for label in all_spans:\n",
    "#         if count > 100:\n",
    "#             break\n",
    "#         for span in all_spans[label]:\n",
    "#             count += 1\n",
    "#             batch_x.append(span)\n",
    "#             batch_y.append(label)\n",
    "#             if len(batch_x) == 60:\n",
    "#                 tokenized = tokenizer(batch_x, return_tensors='pt', padding=True)\n",
    "#                 output = model(**tokenized)\n",
    "#                 x.append(output.last_hidden_state)\n",
    "#                 y.append(batch_y)\n",
    "#                 batch_x = []\n",
    "#                 batch_y = []\n",
    "#             if count % 100 == 0:\n",
    "#                 print(\"Embedding for span %d of %d computed\" % (count, n_spans))\n",
    "#                 print(x[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "691a2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i,key in enumerate(all_spans):\n",
    "    for span in all_spans[key]:\n",
    "        data.append((span, i))\n",
    "\n",
    "import random\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "train = data[:200]\n",
    "test = data[200:300]\n",
    "\n",
    "train_x = [d[0] for d in train]\n",
    "train_y = [[1 if i == d[1] else 0 for i in range(len(all_spans.keys()))] for d in train]\n",
    "train_y = torch.tensor(train_y, dtype=torch.float)\n",
    "test_x = [d[0] for d in test]\n",
    "test_y = [[1 if i == d[1] else 0 for i in range(len(all_spans.keys()))] for d in test]\n",
    "test_y = torch.tensor(test_y, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83dd148b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 195.54608154296875\n",
      "1 175.13975524902344\n",
      "2 144.00485229492188\n",
      "3 114.10669708251953\n",
      "4 91.95745849609375\n",
      "5 76.05500793457031\n",
      "6 65.9549560546875\n",
      "7 58.249267578125\n",
      "8 52.108787536621094\n",
      "9 47.50080871582031\n",
      "10 44.1169319152832\n",
      "11 41.495079040527344\n",
      "12 39.436214447021484\n",
      "13 37.789634704589844\n",
      "14 36.43472671508789\n",
      "15 35.241798400878906\n",
      "16 33.92860412597656\n",
      "17 32.567955017089844\n",
      "18 31.745241165161133\n",
      "19 31.02952766418457\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = SentenceClassifier(list(all_spans.keys()))\n",
    "model.train()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "for t in range(20):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(train_x)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, train_y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bdf223d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "test = model(\"The fed is planning on raising rates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99d570dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(all_spans.keys())\n",
    "\n",
    "pred = int(torch.argmax(test))\n",
    "\n",
    "labels[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4349212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
