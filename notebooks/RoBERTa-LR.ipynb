{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5533ab84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376d8b0463d548ecab77b14e1b6c3788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27c95e50b414d6d80f21ecbcd49cd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f47b675c89f4fc0adf23d9ac1265fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c72135bc50c4b408107f3b4244b80af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eebaf4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec4168b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>Replace me by any text you'd like.</s>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef79fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BatchEncoding as be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d0f32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function transformers.tokenization_utils_base.BatchEncoding.word_ids(self, batch_index:int=0) -> List[Union[int, NoneType]]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be.word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34094c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-30c2be081d11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mn_sequences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     ):\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncodingFast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/_collections_abc.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c8a9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"I hate this guy\", \"I cant stand those people\", \"screw this job, I'm quitting\", \"this is nice\", \"i hope you like it\", \"thank you for helping out!\"]\n",
    "y = [0,0,0,1,1,1]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4023ba93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   100,  4157,    42,  2173,     2,     1,     1,     1,     1],\n",
       "        [    0,   100, 17672,  1413,   167,    82,     2,     1,     1,     1],\n",
       "        [    0,  3866, 10461,    42,   633,     6,    38,   437, 23913,     2],\n",
       "        [    0,  9226,    16,  2579,     2,     1,     1,     1,     1,     1],\n",
       "        [    0,   118,  1034,    47,   101,    24,     2,     1,     1,     1],\n",
       "        [    0, 31653,    47,    13,  1903,    66,   328,     2,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(x, return_tensors='pt', padding = True)\n",
    "model.eval()\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "841a47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a5132cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0636,  0.0658, -0.0253,  ..., -0.0730, -0.0623, -0.0345],\n",
       "         [ 0.0175,  0.0767, -0.0968,  ...,  0.2907, -0.0941, -0.1543],\n",
       "         [ 0.0808,  0.1043,  0.0310,  ...,  0.2646, -0.1021, -0.1503],\n",
       "         ...,\n",
       "         [-0.0517, -0.0447,  0.0486,  ..., -0.0553, -0.0556,  0.1027],\n",
       "         [-0.0517, -0.0447,  0.0486,  ..., -0.0553, -0.0556,  0.1027],\n",
       "         [-0.0517, -0.0447,  0.0486,  ..., -0.0553, -0.0556,  0.1027]],\n",
       "\n",
       "        [[-0.0471,  0.0529, -0.0188,  ..., -0.0893, -0.0566, -0.0265],\n",
       "         [ 0.0552, -0.0501, -0.0416,  ...,  0.1579,  0.0075, -0.1503],\n",
       "         [ 0.0289, -0.1315, -0.1579,  ..., -0.4318, -0.0208,  0.0357],\n",
       "         ...,\n",
       "         [ 0.0859, -0.0279,  0.0401,  ..., -0.0263, -0.1208, -0.0011],\n",
       "         [ 0.0859, -0.0279,  0.0401,  ..., -0.0263, -0.1208, -0.0011],\n",
       "         [ 0.0859, -0.0279,  0.0401,  ..., -0.0263, -0.1208, -0.0011]],\n",
       "\n",
       "        [[-0.0535,  0.0784, -0.0120,  ..., -0.0423, -0.0932,  0.0006],\n",
       "         [-0.1134, -0.1609, -0.1440,  ..., -0.1831, -0.1731,  0.0876],\n",
       "         [ 0.0088, -0.1317,  0.1222,  ..., -0.1297, -0.0445,  0.0264],\n",
       "         ...,\n",
       "         [ 0.0802,  0.1408,  0.0475,  ...,  0.2981, -0.0664, -0.0188],\n",
       "         [ 0.3134,  0.0419, -0.2379,  ...,  0.1719, -0.1082,  0.2173],\n",
       "         [-0.0439,  0.0731, -0.0365,  ..., -0.0683, -0.1002, -0.0186]],\n",
       "\n",
       "        [[-0.0429,  0.0806, -0.0264,  ..., -0.0610, -0.0504, -0.0237],\n",
       "         [ 0.2117,  0.0180,  0.1050,  ...,  0.1539,  0.0347, -0.0405],\n",
       "         [ 0.2213,  0.0566,  0.0413,  ..., -0.1438,  0.1527,  0.1253],\n",
       "         ...,\n",
       "         [ 0.2277, -0.0922,  0.0677,  ..., -0.2097, -0.0258, -0.0657],\n",
       "         [ 0.2277, -0.0922,  0.0677,  ..., -0.2097, -0.0258, -0.0657],\n",
       "         [ 0.2277, -0.0922,  0.0677,  ..., -0.2097, -0.0258, -0.0657]],\n",
       "\n",
       "        [[-0.0614,  0.0748, -0.0197,  ..., -0.0658, -0.0468, -0.0245],\n",
       "         [-0.0026, -0.1051, -0.0464,  ...,  0.0810, -0.1272,  0.1531],\n",
       "         [ 0.0628,  0.1032,  0.2302,  ..., -0.1578,  0.0648,  0.1286],\n",
       "         ...,\n",
       "         [ 0.0300, -0.1695, -0.0226,  ..., -0.1385, -0.0405, -0.1356],\n",
       "         [ 0.0300, -0.1695, -0.0226,  ..., -0.1385, -0.0405, -0.1356],\n",
       "         [ 0.0300, -0.1695, -0.0226,  ..., -0.1385, -0.0405, -0.1356]],\n",
       "\n",
       "        [[-0.0555,  0.0771, -0.0084,  ..., -0.0627, -0.0701,  0.0095],\n",
       "         [-0.0623, -0.1374,  0.0830,  ..., -0.0621,  0.0330,  0.1337],\n",
       "         [-0.0213,  0.0616,  0.0059,  ..., -0.0170,  0.0296, -0.0787],\n",
       "         ...,\n",
       "         [-0.0498,  0.0716, -0.0337,  ..., -0.1023, -0.0807, -0.0041],\n",
       "         [-0.0317, -0.1358,  0.0384,  ..., -0.0697, -0.1909,  0.1034],\n",
       "         [-0.0317, -0.1358,  0.0384,  ..., -0.0697, -0.1909,  0.1034]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0021, -0.2210, -0.2218,  ..., -0.1409, -0.0238, -0.0997],\n",
       "        [-0.0043, -0.2161, -0.2188,  ..., -0.1345, -0.0351, -0.1082],\n",
       "        [ 0.0005, -0.2313, -0.2338,  ..., -0.1431, -0.0349, -0.1101],\n",
       "        [ 0.0013, -0.2122, -0.2132,  ..., -0.1401, -0.0378, -0.1059],\n",
       "        [ 0.0079, -0.2146, -0.2219,  ..., -0.1383, -0.0344, -0.1152],\n",
       "        [ 0.0084, -0.2083, -0.2280,  ..., -0.1337, -0.0470, -0.1050]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5920f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "827e9e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54b14799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lr_input = np.reshape(out.last_hidden_state.detach().numpy(), (6,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e165ba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7680)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70c041d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d095a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
